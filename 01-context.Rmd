# Context 

## Frequentist Methods

The **estimate** is the parameter value which if it was true would be most likely to give rise to the observed data [@millar_maximum_2011]. 

The **95% confidence interval** is the range of parameter values which if they were true would have a 5% or greater probability of giving rise to data with a parameter estimate no more extreme than that observed.

The **p-value** is the probability that if the true parameter value was 0 (no effect) that it would give rise to data with a parameter estimate no more extreme than that observed.

By convention a p-value < 0.05 is statistically **significant** and this is equivalent to a 95% confidence interval that does not span 0 (no effect).

The **power** is the probability that a p-value will be *significant* for a particular parameter value and sample size.

## Bayesian Methods

Bayesian methods multiply the probability of each parameter value giving rise to the observed data by the prior probability of the parameter value being true to get the probability of each parameter values being true given the observed data.

The resultant probability distribution provides a complete summary of the uncertainty although it can be summarized in terms of an estimate (often median), a 95% credible interval (typically 95% quantiles) which has a 95% probability of including the true value and a p-value which is the probability of the true effect being in the opposite direction to the estimate. 
In this case statistically significance indicates that the probability that the true effect is in the opposite direction to the estimate is < 0.05.

## Significance and Effect Sizes

In 2016 the American Association [@wasserstein_asas_2016] provided a statement on p-values.
It included the following 

**Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.**

> Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “p < 0.05”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making...Pragmatic considerations often require binary, “yes-no” decisions, but this does not mean that p-values alone can ensure that a decision is correct or incorrect. 


**A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.**

> Statistical significance is not equivalent to scientific, human, or economic significance. 
Smaller p-values do not necessarily imply the presence of larger or more important effects, and larger p-values do not imply a lack of importance or even lack of effect. 
Any effect, no matter how tiny, can produce a small p-value if the sample size or measurement precision is high enough, and large effects may produce unimpressive p-values if the sample size is small or measurements are imprecise. 
