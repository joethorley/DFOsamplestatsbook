# Theoretical Background

## Frequentist Methods

In frequentist methods, the **estimate** is the parameter value which if it was true would be most likely to give rise to the observed data [@millar_maximum_2011].

The **95% confidence interval** is the range of parameter values which if they were true would have a 5% or greater probability of giving rise to data with a parameter estimate no more extreme than that observed.

The **p-value** is the probability that if the true parameter value was 0 (no effect) that it would give rise to data with a parameter estimate no more extreme than that observed.

By convention a p-value \< 0.05 is statistically **significant** and this is equivalent to a 95% confidence interval that does not span 0 (no effect).

The **power** is the probability that a p-value will be *significant* for a particular parameter value and sample size.

As is always the case the values are conditional on the assumptions of the model being correct.

## Bayesian Methods

Bayesian methods multiply the probability of each parameter value giving rise to the observed data by the prior probability of the parameter value being true to get the probability of each parameter value being true given the observed data.

The resultant probability distribution provides a complete representation of the uncertainty although it can be summarized in terms of an estimate (often median), a 95% credible interval (typically 95% quantiles) which has a 95% probability of including the true value and a p-value which is the probability of the true effect being in the opposite direction to the estimate. Statistical significance and power are as defined above for frequentist methods.

@jaynes_probability_2003 mathematically proves that Bayesian methods represent the extension of formal logic from certain to uncertain situations.

Thus while formal logic can proceeds as follows

> All sharks are fish.

Therefore

- If an object is a shark it is as fish.
- If an object is not a fish it is not a shark.

Bayesian inference can take a statement like

- If an object is probably a shark what is the probability it is fish.
- If an object is a fish what is the probability it is shark.

## Frequentist vs Bayesian

Standard frequentist methods typically use fast heuristics but their validity depends on the sample size.

Standard Bayesian methods can be slower to fit but do not depend on the sample size; can readily handle missing values; and allow the uncertainty in derived parameters to be quantified.

Frequentist analyses can, and generally are, interpreted as Bayesian analyses with uninformative priors [@jaynes_probability_2003; @mcelreath_statistical_2020]. 
If prior information is available then its incorporation leads to more reliable estimates [@jaynes_probability_2003; @mcelreath_statistical_2020], particularly with small sample sizes.

In this sense frequentist methods can be viewed as a form of Bayesian heuristic [@jaynes_probability_2003].

## P-values

In 2016 the American Statistical Association [@wasserstein_asas_2016] provided a statement on p-values. 
It included the following

**A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.**

> Smaller p-values do not necessarily imply the presence of larger or more important effects, and larger p-values do not imply a lack of importance or even lack of effect. 
Any effect, no matter how tiny, can produce a small p-value if the sample size or measurement precision is high enough, and large effects may produce unimpressive p-values if the sample size is small or measurements are imprecise.

In other words, p-values confound the estimated size of the effect with the uncertainty (width of the confidence interval) which is what they were intended to do [@greenland2019]. 
The solution is to also report the estimate and associated confidence/credible intervals; an approach sometimes referred to as effect size estimation/reporting.

**Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.**

> Practices that reduce data analysis or scientific inference to mechanical 'bright-line' rules (such as 'p \< 0.05') for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making...Pragmatic considerations often require binary, 'yes-no' decisions, but this does not mean that p-values alone can ensure that a decision is correct or incorrect.

Important decisions should be based on decision analysis, ie the estimated consequences (with uncertainty) of alternative actions on human values [@hemming_introduction_2022].
And data collection, which is itself a form of decision, should be based on the probable benefits of improving a decision versus the cost of collecting the data [@canessa2015]. 

However, less consequential data collections decisions such as how many salmonids to sample or tag can be based on simpler heuristics such as the expected power.

## Power Analysis

Power analysis can be used to determine how much data to collect to have a reasonable probability (typically 0.8) of a statistically significant result (typically p-value \< 0.05) for a given effect size.

It is worth noting that once a sample has been collected a post-hoc power analysis provides no information beyond that already provided by the estimated effect size [@colegrave_confidence_2003].

To understand the inter-dependence among effect size and power consider that a power analysis can be used to determine how the uncertainty in an estimate (width of the CI) will vary with the sample size.

In the case of very simple models, equations have been developed to allow the power to be quickly calculated.
More complex models require thousands of data sets to be simulated and analysed which depending on the complexity of the model can require a lot of computational time.

## Summary

In short the use of frequentist power analyses to determine the number of salmon to tag and recapture can be viewed and justified as a quick Bayesian Decision Analytic heuristic.

However, it is important to have a general understanding of the theoretical background so that if frequentist power analysis proves inadequate for a particular problem it is clear how to alter it to make an informed decision.
